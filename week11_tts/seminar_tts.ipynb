{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "name": "seminar_tts.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CFYpvF5NYJDE",
        "colab_type": "text"
      },
      "source": [
        "# Text to Speech\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yNfJOv-cYJDO",
        "colab_type": "text"
      },
      "source": [
        "![this should be a picture](https://i.imgur.com/WQXFdci.png)\n",
        "\n",
        "Last week was all about sound processing: you learned about audio files, spectrograms and even trained a simple speech classifier on top of that. This time we'll do the same, but the other way around: the should take text as an input and generate sound from that. Jump in! it's gonna be fun :)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JKHAeXy-YJDW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import json\n",
        "import glob\n",
        "import numpy as np\n",
        "import random"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wc4bm4oxYJDu",
        "colab_type": "text"
      },
      "source": [
        "## Data\n",
        "We took LJSpeech and carefully extracted features (Mels-specs and phone alignment) so you don't have to.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sdrYtiXRYJDy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install librosa tensorflow-gpu==2.1.0rc0\n",
        "!wget https://www.dropbox.com/s/fmvi648spv8xjxd/cmudict.dict?dl=1 -O cmudict.dict\n",
        "!wget https://www.dropbox.com/s/ihhs20xws1jstvu/dataset-aligned.tar?dl=1 -O dataset-aligned.tar\n",
        "!wget https://www.dropbox.com/s/zvyqz4ovx84gaw1/waveglow_256channels.pt?dl=1 -O waveglow_256channels.pt\n",
        "!tar -xf dataset-aligned.tar"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w1Qjji84YJEJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "all_rows = [\n",
        "    json.load(open(fname, encoding='utf8'))\n",
        "    for fname in glob.glob('dataset-aligned/*.json')\n",
        "]\n",
        "assert len(all_rows) == 13100\n",
        "\n",
        "id2utt = {row['ID']: row['utterance'] for row in all_rows if 'utterance' in row}\n",
        "\n",
        "all_ids = sorted(id2utt.keys())\n",
        "assert len(id2utt) == 13071\n",
        "\n",
        "NMels = 80\n",
        "\n",
        "id2mel = {\n",
        "    ID: np.load('dataset-aligned/{}.mel.npy'.format(ID))\n",
        "    for ID in id2utt\n",
        "}\n",
        "for mels in id2mel.values():\n",
        "    assert mels.shape[0] == NMels\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_FL2UJt-YJEd",
        "colab_type": "text"
      },
      "source": [
        "## What is in an utterance?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mA2B5p6aYJEg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "id2utt[all_ids[1231]]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8NSGncHDYJEp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def ms2frames(ms, SR=22050, hop_length = 256):\n",
        "    return int(ms / 1000 * SR / hop_length)\n",
        "\n",
        "def show_utt(utt, mels, contour=False):\n",
        "    print(' '.join(w['text'] for w in utt['words']).replace('yandexttsspecialpauseword', 'PAUSE'))\n",
        "    plt.figure(figsize=[mels.shape[1] / 10, 5])\n",
        "    plt.imshow(mels[::-1], aspect='auto')\n",
        "    if contour:\n",
        "        plt.contour(mels[::-1], levels = 5,colors='w')\n",
        "    for word in utt['words']:\n",
        "        onset = ms2frames(word['phones'][0]['onset'])\n",
        "        plt.text(onset + 1, -20, word['text'].replace('yandexttsspecialpauseword', 'PAUSE'))\n",
        "        plt.plot([onset] * 2, [-20, 0], 'k')\n",
        "        for phone in word['phones']:\n",
        "            onset = ms2frames(phone['onset'])\n",
        "            plt.text(onset + 1, -10, phone['phone'])\n",
        "            plt.plot([onset] * 2, [-10, 0], 'k')\n",
        "            plt.plot([onset] * 2, [80, 0], 'w')\n",
        "    plt.show()\n",
        "    \n",
        "ID = all_ids[45]\n",
        "show_utt(id2utt[ID], id2mel[ID])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RxTdmwH7YJE1",
        "colab_type": "text"
      },
      "source": [
        "## Listen\n",
        "We'll use a pre-trained Waveglow vocoder:\n",
        "https://github.com/NVIDIA/waveglow\n",
        "\n",
        "It's written in PyTorch. If you need to install it locally, [here](https://pytorch.org/)'s how you do that."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mjlLJI34YJE4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git clone https://github.com/NVIDIA/tacotron2.git\n",
        "!cd tacotron2 && git submodule update --init"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xMYT_5VjYJFA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Import and load model\n",
        "import torch\n",
        "import sys\n",
        "torch_device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "if torch_device == 'cpu':\n",
        "  torch.cuda.FloatTensor = torch.FloatTensor  # dirty trick to run old WaveGlow\n",
        "\n",
        "WGP = 'tacotron2/waveglow/'\n",
        "if WGP not in sys.path:\n",
        "    sys.path.append(WGP)\n",
        "\n",
        "waveglow_path = 'waveglow_256channels.pt'\n",
        "waveglow = torch.load(waveglow_path, map_location=torch_device)['model']\n",
        "waveglow.to(torch_device).train(False)\n",
        "if torch_device == 'cuda':\n",
        "    waveglow = waveglow.half()\n",
        "    for k in waveglow.convinv:\n",
        "        k.float()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FGTgWlEvYJFK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Synthesize and listen\n",
        "## Don't mind the warnings, it's an old model checkpoint\n",
        "import IPython.display as ipd\n",
        "def synthesize(mels, SR=22050):\n",
        "    with torch.no_grad():\n",
        "        torch_batch = torch.as_tensor(\n",
        "            mels[None, :, :], device=torch_device, \n",
        "            dtype=torch.float16 if torch_device=='cuda' else torch.float32)\n",
        "        audio = waveglow.infer(torch_batch, sigma=1)\n",
        "    ipd.display(ipd.Audio(audio[0].data.cpu().numpy(), rate=SR, autoplay=True))\n",
        "\n",
        "\n",
        "synthesize(id2mel[all_ids[32]])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m-9oOcZOYJFS",
        "colab_type": "text"
      },
      "source": [
        "## Build phoneme dictionary (the usual)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "FtOT0DovYJFV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from collections import Counter\n",
        "phone_counts = Counter(\n",
        "    phone['phone'] \n",
        "    for utt in id2utt.values() \n",
        "    for word in utt['words'] \n",
        "    for phone in word['phones']\n",
        ")\n",
        "PAD = '_PAD'\n",
        "\n",
        "# Task: create phoneme vocabulary that maps phonemes to ids\n",
        "# Note: your words should be sorted by python string order\n",
        "all_phones = <YOUR CODE HERE>\n",
        "phone2idx = <YOUR CODE HERE>\n",
        "assert len(all_phones) == 55\n",
        "assert all_phones[-1] == PAD\n",
        "assert phone2idx[all_phones[0]] == 0\n",
        "assert phone2idx[all_phones[13]] == 13\n",
        "assert phone2idx[all_phones[-1]] == 54\n",
        "\n",
        "print('All good!')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1wo-M1HgYJFe",
        "colab_type": "text"
      },
      "source": [
        "## Let's look at data:\n",
        "### Phone durations histogram"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UJUh5bz1YJFg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "all_durations = np.array([phone['duration'] for utt in id2utt.values() for word in utt['words'] for phone in word['phones']])\n",
        "plt.hist(all_durations, bins=100, log=True)\n",
        "plt.show()\n",
        "print('mean={}'.format(np.mean(all_durations)))\n",
        "print('median={}'.format(np.median(all_durations)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EYItFRetYJFn",
        "colab_type": "text"
      },
      "source": [
        "### Sentence lengths in frames and in phones:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yxojkugPYJFp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#sent lengths in frames and in phones:\n",
        "\n",
        "phone_counts = [sum(len(word['phones']) for word in utt['words']) for utt in id2utt.values()]\n",
        "frame_counts = [mels.shape[1] for mels in id2mel.values()]\n",
        "\n",
        "plt.figure(figsize=[10,10])\n",
        "plt.subplot(2,2,1)\n",
        "plt.hist(phone_counts, bins=30)\n",
        "plt.subplot(2,2,2)\n",
        "plt.plot(sorted(phone_counts))\n",
        "\n",
        "plt.subplot(2,2,3)\n",
        "plt.hist(frame_counts, bins=30)\n",
        "plt.subplot(2,2,4)\n",
        "plt.plot(sorted(frame_counts))\n",
        "plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7wfXdL11YJFx",
        "colab_type": "text"
      },
      "source": [
        "### Melspec distributions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mGJHn10yYJFz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "some_mels = np.concatenate([id2mel[ID] for ID in random.sample(all_ids, 100)], axis=1)\n",
        "\n",
        "mel_means = np.mean(some_mels, axis=1)\n",
        "mel_stds = np.std(some_mels, axis=1)\n",
        "\n",
        "plt.plot(mel_means, label='mean')\n",
        "plt.plot(mel_means + mel_stds, label = 'mean + std')\n",
        "plt.plot(mel_means - mel_stds, label = 'mean - std')\n",
        "plt.plot(mel_stds, label = 'std')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "mel_corr = np.corrcoef(some_mels)\n",
        "plt.imshow(mel_corr)\n",
        "plt.show()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iDtAyg9mYJF8",
        "colab_type": "text"
      },
      "source": [
        "## Generating batches"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bJ43BUQxYJF-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from collections import namedtuple\n",
        "\n",
        "TtsBatch = namedtuple('TtsBatch', [\n",
        "    'phone_idxs', # (B x Lenc), int\n",
        "    'phone_durs', # (B x Lenc), float\n",
        "    'alignment',  # (B x Ldec), int\n",
        "    'mels',       # (B x Ldec x Nmels), float\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tJgD8gtyYJGD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def gen_batch(ids):\n",
        "    \"\"\" Assemble training batch from sample indices \"\"\"\n",
        "    utts = [id2utt[ID] for ID in ids]\n",
        "    phone_seqs = [[phone2idx[phone['phone']] for word in utt['words'] for phone in word['phones']] for utt in utts]\n",
        "    phone_durs = [[phone['duration'] for word in utt['words'] for phone in word['phones']] for utt in utts]\n",
        "    phone_seq_mat = np.full([len(ids), max(map(len, phone_seqs))], phone2idx[PAD], dtype='int32')\n",
        "    phone_dur_mat = np.ones([len(ids), max(map(len, phone_seqs))], dtype='float32')\n",
        "    for i, (idxs, durs) in enumerate(zip(phone_seqs, phone_durs)):\n",
        "        phone_seq_mat[i, :len(idxs)] = idxs\n",
        "        phone_dur_mat[i, :len(idxs)] = durs\n",
        "        \n",
        "        \n",
        "    mels = [id2mel[ID] for ID in ids]\n",
        "    mel_lengths = np.array([mel.shape[1] for mel in mels], dtype='int32')\n",
        "    mel_mat = np.full([len(ids), max(mel_lengths), NMels], -1, dtype='float32')\n",
        "    mel_aligns = np.full([len(ids), max(mel_lengths)], -1, dtype='int32')\n",
        "    for i, mel in enumerate(mels):\n",
        "        mel_mat[i,  :mel_lengths[i]] = mel.T\n",
        "        for j, phone in enumerate(phone for word in utts[i]['words'] for phone in word['phones']):\n",
        "            start = ms2frames(phone['onset'])\n",
        "            finish = ms2frames(phone['onset'] + phone['duration'])\n",
        "            mel_aligns[i, start:finish] = j\n",
        "    return TtsBatch(\n",
        "        phone_idxs=phone_seq_mat,\n",
        "        phone_durs=phone_dur_mat,\n",
        "        alignment=mel_aligns,\n",
        "        mels=mel_mat\n",
        "    )\n",
        "    \n",
        "    \n",
        "gen_batch(all_ids[:1])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EjAJ5ltbYJGM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "valid_ids = all_ids[:100]\n",
        "train_ids = all_ids[100:]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dtCFTlgFYJGS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.python.client import device_lib\n",
        "\n",
        "is_gpu_available = any(device.device_type == 'GPU' for device in device_lib.list_local_devices())\n",
        "device = '/device:GPU:0' if is_gpu_available else '/device:CPU:0'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M7jvKjCFYJGc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "assert tf.__version__.startswith('2'), \"Current tf version: {}; required: 2.0.*\".format(tf.__version__)\n",
        "L = tf.keras.layers\n",
        "keras = tf.keras\n",
        "\n",
        "class Model(L.Layer):\n",
        "    def __init__(\n",
        "        self, \n",
        "        phone_count=len(all_phones), \n",
        "        emb_size=128, \n",
        "        enc_hid_size=128, \n",
        "        dec_hid_size=128,\n",
        "    ):\n",
        "        super().__init__() # initialize base class to track sub-layers, trainable variables, etc.\n",
        "\n",
        "        # Phoneme embedding\n",
        "        self.emb = L.Embedding(phone_count, emb_size)\n",
        "        # Encoder cell\n",
        "        self.encoder = L.GRU(enc_hid_size, return_sequences=True)\n",
        "        # Duration predictor\n",
        "        self.dur_linear = L.Dense(\n",
        "            1, bias_initializer=keras.initializers.constant(np.mean(all_durations))\n",
        "            # Karpathy's trick: http://karpathy.github.io/2019/04/25/recipe/\n",
        "\n",
        "        )\n",
        "        # Decoder cell\n",
        "        self.decoder = L.GRU(dec_hid_size, return_sequences=True, return_state=True)\n",
        "\n",
        "        # Melspec predictor\n",
        "        self.mel_projection = L.Dense(\n",
        "            NMels, bias_initializer=keras.initializers.constant(mel_means)\n",
        "        ) \n",
        "        \n",
        "        self.zeroth_mel = tf.Variable(np.random.normal(size=[NMels]), dtype='float32', name='zero_mel')\n",
        "\n",
        "    def encode(self, \n",
        "               phone_idxs, # B x Lenc\n",
        "               train=False):\n",
        "        # Encode phonemes and predict durations from hidden state.\n",
        "        # You should use: emb, encoder, dur_linear\n",
        "        <YOUR_CODE>\n",
        "        return (\n",
        "            durations , # B x Lenc x 1\n",
        "            hid_state   # B x Lenc x Henc\n",
        "        )\n",
        "    \n",
        "\n",
        "    def decode(self, \n",
        "               encoded,    # B x Lenc x Henc\n",
        "               alignments, # B x Ldec\n",
        "               prev_mels,  # B x Ldec x NMels\n",
        "               prev_states, # None or list of RNN cell(s) states\n",
        "               train=False):\n",
        "        encoded_upsampled = tf.gather_nd(encoded, tf.maximum(0, alignments[:,:,None]), batch_dims=1)\n",
        "        X = tf.concat([encoded_upsampled, prev_mels], axis=2)\n",
        "\n",
        "        # Run decoder recurrent network over X. Start from prev_states\n",
        "        # After that you can predict next mels using mel_projection\n",
        "        <YOUR_CODE>\n",
        "    \n",
        "        return (\n",
        "            mels,      # B x Ldec X NMels\n",
        "            new_states # list of states\n",
        "        )\n",
        "    \n",
        "    def forward_train(self, batch, train=False):\n",
        "        # This runs the model in train mode for calculating loss + optionally gradients,\n",
        "        # using teacher forcing on mels\n",
        "        \n",
        "        # Prepare\n",
        "        zeroth_mel = tf.tile(self.zeroth_mel[None, None, :], [batch.mels.shape[0], 1, 1])\n",
        "        prev_mels = tf.concat([zeroth_mel, batch.mels[:,:-1]], axis=1)\n",
        "        prev_states = [None]\n",
        "        \n",
        "        #Run encoder\n",
        "        durs, encoded = self.encode(batch.phone_idxs, train=train)\n",
        "        #Run decoder\n",
        "        mel_preds, _ = self.decode(encoded, batch.alignment, prev_mels, prev_states, train=train)\n",
        "        \n",
        "        return durs, mel_preds\n",
        "    \n",
        "    def forward_inference(self, \n",
        "                          phone_idx # Is flattened, doesn't work with batches\n",
        "                          ):\n",
        "        # This runs the model in inference mode, using its own predicted durations and mels from prev. step\n",
        "        prev_mels = self.zeroth_mel[None, None, :]\n",
        "        prev_states = [None]\n",
        "        # Run encoder\n",
        "        durs, encoded = self.encode(phone_idx.reshape([1,-1]))\n",
        "        # Convert frame durations to alignments\n",
        "        frame_durs = list(map(ms2frames, durs[0]))\n",
        "        frame_durs = np.maximum(1, np.array(frame_durs))\n",
        "        full_alignment = np.array(sum([[i] * frames for i, frames in enumerate(frame_durs)], []))\n",
        "        \n",
        "        # Run decoder, one step at a time, reusing previous states and mels\n",
        "        result = []\n",
        "        for frame_alignment in full_alignment:\n",
        "            mel_preds, states = self.decode(encoded, np.full([1,1], frame_alignment), prev_mels, prev_states)\n",
        "            result.append(mel_preds)\n",
        "            prev_mels, prev_states = mel_preds, states\n",
        "            \n",
        "        # Collect mels\n",
        "        mels = tf.concat(result, axis=1)\n",
        "        return mels\n",
        "    \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TVC8GAqfYJGh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf.random.set_seed(1337)\n",
        "np.random.seed(1337)\n",
        "\n",
        "model = Model()\n",
        "batch = gen_batch(all_ids[78:80])\n",
        "dur_pred, mel_pred = model.forward_train(batch)\n",
        "assert dur_pred.shape == (2, 75, 1) \n",
        "assert mel_pred.shape ==  (2, 583, 80)\n",
        "assert np.allclose(dur_pred[:,20,0].numpy(), [88.01232, 88.02252])\n",
        "assert np.allclose(mel_pred[0, 100, :5].numpy(), [-6.5848618, -6.194147 , -6.006989 , -4.6337852, -3.1684837], atol=0.1, rtol=0.1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6D9QqFRZYJGo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mels = model.forward_inference(batch.phone_idxs)\n",
        "assert mels.shape == (1, 1050, 80)\n",
        "print(mels.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zrz81YopYJGx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "[(v.name, v.shape) for v in model.trainable_variables]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o3QpMIWBYJG2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def dur_loss(\n",
        "    dur_true,  # B x Lenc x 1\n",
        "    dur_pred,  # B x Lenc x 1\n",
        "    phone_idxs # phoneme indices B x Lenc\n",
        "    ):\n",
        "    mask = tf.cast(phone_idxs != phone2idx[PAD], dtype='float32') # B x Lenc\n",
        "\n",
        "    # Evaluate Mean Absolute Error (L1) between predicted and true durations\n",
        "    # Note: your should average loss only over cells where mask equals True\n",
        "    <YOUR CODE HERE>\n",
        "\n",
        "    return <YOUR LOSS>\n",
        "\n",
        "\n",
        "def mel_loss(mel_true, mel_pred, alignments):\n",
        "    mask = tf.cast(alignments >= 0, dtype='float32')\n",
        "\n",
        "    # Compute Mean Squared Error (L2) between predicted and true mel spectres\n",
        "    # Note: same as before, you should account for mask when averaging\n",
        "\n",
        "    <YOUR CODE HERE>\n",
        "    return <YOUR LOSS>\n",
        "\n",
        "batch = gen_batch([all_ids[78]])\n",
        "dur_pred, mel_pred = model.forward_train(batch)\n",
        "\n",
        "loss_dur = dur_loss(batch.phone_durs, dur_pred, batch.phone_idxs)\n",
        "assert loss_dur.shape == ()\n",
        "assert np.allclose(loss_dur.numpy() / 30, 1.3000526, rtol=1e-2, atol=1e-2)\n",
        "\n",
        "loss_mel = mel_loss(batch.mels, mel_pred, batch.alignment)\n",
        "assert loss_mel.shape == ()\n",
        "assert np.allclose(loss_mel.numpy(), 3.4176075, rtol=1e-2, atol=1e-2)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dtTfgAHNYJG8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with tf.device(device):\n",
        "    metrics = {'train_loss': [], 'valid_loss': [] }\n",
        "    model = Model()\n",
        "    opt = keras.optimizers.Adam(1e-3)\n",
        "    batch_size = 16"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "kLkPddnEYJHD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "valid_batch = gen_batch(valid_ids)\n",
        "with tf.device(device):\n",
        "    while True:\n",
        "        print(end='.')\n",
        "        batch = gen_batch(random.sample(train_ids, batch_size))\n",
        "        step = len(metrics['train_loss']) + 1\n",
        "\n",
        "        with tf.GradientTape() as tape:\n",
        "            dur_pred, mel_pred = model.forward_train(batch)\n",
        "            loss_dur = dur_loss(batch.phone_durs, dur_pred, batch.phone_idxs)\n",
        "            loss_mel = mel_loss(batch.mels, mel_pred, batch.alignment)\n",
        "            loss_t = loss_dur + loss_mel\n",
        "\n",
        "        grads = tape.gradient(loss_t, model.trainable_variables)\n",
        "        opt.apply_gradients(zip(grads, model.trainable_variables))\n",
        "        metrics['train_loss'].append((step, loss_t.numpy(), loss_dur.numpy(), loss_mel.numpy()))\n",
        "        if step % 20 == 0:\n",
        "            dur_pred, mel_pred = model.forward_train(valid_batch)\n",
        "            loss_dur = dur_loss(valid_batch.phone_durs, dur_pred, valid_batch.phone_idxs)\n",
        "            loss_mel = mel_loss(valid_batch.mels, mel_pred, valid_batch.alignment)\n",
        "            loss_v = loss_dur + loss_mel\n",
        "            metrics['valid_loss'].append((step, loss_v.numpy(), loss_dur.numpy(), loss_mel.numpy()))\n",
        "\n",
        "            ipd.clear_output(True)\n",
        "            plt.figure(figsize=(12,4))\n",
        "            for i, (name, history) in enumerate(sorted(metrics.items())):\n",
        "                plt.subplot(1, len(metrics), i + 1)\n",
        "                plt.title(name)\n",
        "                history = np.array(history, dtype='float32').T\n",
        "                plt.plot(history[0], history[1:].T)\n",
        "                plt.grid()\n",
        "                plt.legend(['total', 'duration', 'mel_pred'])\n",
        "            plt.show()\n",
        "            synthesized = mel_pred[0, :id2mel[valid_ids[0]].shape[1]].numpy().T\n",
        "            show_utt(id2utt[valid_ids[0]], id2mel[valid_ids[0]])\n",
        "            show_utt(id2utt[valid_ids[0]], synthesized)\n",
        "            print(\"Mean loss=%.3f, valid=%.3f\" % (np.mean(metrics['train_loss'][-10:], axis=0)[1], \n",
        "                                                  metrics['valid_loss'][-1][1]), flush=True)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jr6prCL-YJHH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mels = model.forward_inference(valid_batch.phone_idxs[8][:36])\n",
        "mels = mels.numpy()\n",
        "synthesize(mels[0].T)\n",
        "plt.imshow(mels[0,::-1].T)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KREMCjlJYJHQ",
        "colab_type": "text"
      },
      "source": [
        "For Text2Speech we need a dictionary\n",
        "\n",
        "https://github.com/cmusphinx/cmudict"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "suVKDYl1YJHS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load dictionary\n",
        "\n",
        "import collections\n",
        "import re\n",
        "en_g2p_dict = collections.defaultdict(list)\n",
        "phone_remapping = {\n",
        "    'AA0': 'AA1',\n",
        "    'AA2': 'AA1',\n",
        "    'AE2': 'AE1',\n",
        "    'AH2': 'AH1',\n",
        "    'AO2': 'AO1',\n",
        "    'AW2': 'AW1',\n",
        "    'AY2': 'AY1',\n",
        "    'EH2': 'EH1',\n",
        "    'ER0': 'EH1',\n",
        "    'ER1': 'EH1',\n",
        "    'ER2': 'EH1',\n",
        "    'EY2': 'EY1',\n",
        "    'IH2': 'IH1',\n",
        "    'IY2': 'IY1',\n",
        "    'OW2': 'OW1',\n",
        "    'OY2': 'OY1',\n",
        "    'UH2': 'UH1',\n",
        "    'UW2': 'UW1',\n",
        "}\n",
        "\n",
        "with open('cmudict.dict') as f:\n",
        "    for l in f:\n",
        "        l = re.sub(r'#.*', '', l.strip())\n",
        "        parts = l.split()\n",
        "        word = parts[0]\n",
        "        word = re.sub(r'\\(.*\\)', '', word)\n",
        "        phones = parts[1:]\n",
        "        phones = [phone_remapping[ph] if ph in phone_remapping else ph for ph in phones]\n",
        "        assert all(ph in all_phones for ph in phones) \n",
        "        en_g2p_dict[word].append(phones)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "osMsezj3YJHW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Here you can add custom words\n",
        "custom_dict = {\n",
        "    'waveglow': 'W EY1 V G L OW0'.split(),\n",
        "    'spartaaa': 'S P AH1 R T AH1 AH1 AH1'.split()\n",
        "}\n",
        "for pron in custom_dict.values():\n",
        "    for ph in pron:\n",
        "        assert ph in phone2idx"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7HHK2bhcYJHb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Preprocessor: Text -> phone indexes\n",
        "\n",
        "from nltk.tokenize import WordPunctTokenizer\n",
        "tokenizer = WordPunctTokenizer()\n",
        "\n",
        "def preprocess(sent):\n",
        "    words = tokenizer.tokenize(sent.lower())\n",
        "    phones = []\n",
        "    for word in words:\n",
        "        if re.fullmatch(r'[^a-z]*', word):\n",
        "            phones += ['pau']\n",
        "        elif word in custom_dict:\n",
        "            phones += custom_dict.get(word)\n",
        "        elif word in en_g2p_dict:\n",
        "            phones += en_g2p_dict.get(word)[0]\n",
        "        else:\n",
        "            raise ValueError('No transcription for word \"{}\"\"'.format(word))\n",
        "    phone_idxs = [phone2idx[phone] for phone in phones]\n",
        "    return phone_idxs\n",
        "\n",
        "preprocess('My waveglow!')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0c-cA1VRxuim",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VmQfQ6TnYJHf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Finally synthesize!\n",
        "\n",
        "text = 'This. . . is. . .  SPARTAAA!!!!!'\n",
        "mels = model.forward_inference(np.array(preprocess(text)))\n",
        "mels = mels.numpy()[0].T\n",
        "synthesize(mels)\n",
        "\n",
        "plt.imshow(mels[::-1])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SFp8bxDtwuud",
        "colab_type": "text"
      },
      "source": [
        "## Alternative vocoder\n",
        "\n",
        "Below we implement a simple algorithmic vocoder from pre-wavenet era\n",
        "Feel free to try it and see find out which works best for you :)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bdRsTw3WxXa9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UCd_8qwsYJHk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import scipy.signal as dsp\n",
        "import librosa.filters as filters\n",
        "import scipy.interpolate as interp\n",
        "mel_filters = filters.mel(22050, 1024, fmin=0, fmax=8000, n_mels=NMels)\n",
        "mel_inv = np.linalg.pinv(mel_filters)\n",
        "\n",
        "def robot_synth(mels, speed=1., spectr_deform=1.):\n",
        "    assert mels.shape[0] == 80 and mels.ndim == 2\n",
        "    spectr = np.exp(mels).T @ mel_inv.T\n",
        "    phase = np.random.uniform(0, 1, size=[1,513])\n",
        "    spectr = spectr * np.exp(2j * np.pi * phase)\n",
        "    _, waveform = dsp.istft(spectr.T, nperseg=1024, noverlap=int(1024 - (256 / speed)))\n",
        "    ipd.display(ipd.Audio(data=waveform, rate=22050, autoplay=True))\n",
        "    \n",
        "\n",
        "robot_synth(mels[0].T, speed=0.7)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EPP3uu-wx3x2",
        "colab_type": "text"
      },
      "source": [
        "Homework assignment: __TBA__"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "APkMZam0x6fF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}