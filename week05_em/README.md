#### Generative Models, Expectation-Maximization and Hidden Markov Models

Today's lecture will cover generative models, maximum likelihood estimation from incomplete data using Expectation-Maximization and Hidden Markov models.

The Expectation-Maximization algorithm is a general algorithm for estimating models when some variables are not observed. We'll eventually use it to learn alignments between words in parallel text, but today we'll focus on some toy examples and some deciphering problems.

* (Slides ) [Generative models and EM](https://github.com/yandexdataschool/nlp_course/blob/2019/week05_em/generative_models_and_em.pdf) 
* First exercise on MLE and EM [notebook](coins-seminar.ipynb)
* Homework notebook using HMM to decipher text [notebook](hmm-seminar.ipynb) This homework is worth 15 points and is due by the next class (17th Oct.), please submit the results of the last task (a list of files and names of the author/work) to Anytask in the following format: 'filename author' where 'filename' is a file from 'encrypted/*_encrypted.txt' and 'author' is a file from 'plaintext/*' (not including 'english.txt', 'russian.txt' or 'all.txt') which best matches.


